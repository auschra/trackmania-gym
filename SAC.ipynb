{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.policies import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mss\n",
    "import pygetwindow as gw\n",
    "import easyocr as ocr\n",
    "\n",
    "import pydirectinput\n",
    "import vgamepad as vg\n",
    "\n",
    "import psutil\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\easyocr\\detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "c:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\easyocr\\recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "class Reader:\n",
    "    def __init__(self):\n",
    "        self.reader = ocr.Reader(['en'], model_storage_directory='./ocr_model')\n",
    "\n",
    "    def read(self, img):\n",
    "        speed_text = self.reader.readtext(img, allowlist='0123456789')\n",
    "        return speed_text\n",
    "\n",
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of window to get x, y, w, h \n",
    "speed_rect = [1, 12, 45, 30]\n",
    "done_rect = [130, 40, 50, 60]\n",
    "\n",
    "# get pixel values of window\n",
    "def get_screen():\n",
    "    window = gw.getWindowsWithTitle('Trackmania')[0]\n",
    "    border_pixels = [40, 12, 40, 10] # top, left, right, bottom\n",
    "    # get picture of screen\n",
    "    with mss.mss() as sct:\n",
    "        monitor = {\"top\": window.top + border_pixels[0], \n",
    "                   \"left\": window.left + border_pixels[1], \n",
    "                   \"width\": window.width - border_pixels[1] - border_pixels[2], \n",
    "                   \"height\": window.height - border_pixels[0] - border_pixels[3]}\n",
    "        img = np.array(sct.grab(monitor))\n",
    "    return img\n",
    "\n",
    "# get the current speed and check region of screen for finish\n",
    "def get_speed_done(img): \n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    speed = img[speed_rect[1]:speed_rect[1]+speed_rect[3], speed_rect[0]:speed_rect[0]+speed_rect[2]]\n",
    "    speed_text = reader.read(speed)\n",
    "    done = img[done_rect[1]:done_rect[1]+done_rect[3], done_rect[0]:done_rect[0]+done_rect[2]]\n",
    "    done_text = reader.read(done)\n",
    "    if speed_text:\n",
    "        speed = speed_text[0][1]\n",
    "    else:\n",
    "        speed = 0\n",
    "    done = bool(done_text)\n",
    "    return speed, done      # int?, bool\n",
    "\n",
    "# convert to grayscale, cut off extra not need for driving\n",
    "\n",
    "\n",
    "# 84x84x1 for customcnn\n",
    "#224x244 for resnet 18\n",
    "def process_screen_pov(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = img.shape\n",
    "    img = img[height//2: height-50, :]\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)    \n",
    "    img = cv2.Canny(img, 100, 150)\n",
    "    # canny edge detection\n",
    "    img = cv2.resize(img, (84, 84))\n",
    "    img = img / 255.0               # [0, 1]\n",
    "    return img.astype(np.float32) # (1, 84, 84)\n",
    "\n",
    "def process_screen_3rd(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = img.shape\n",
    "    img = img[height//3: height-70, :]\n",
    "    #img = cv2.GaussianBlur(img, (5, 5), 0)    \n",
    "    #img = cv2.Canny(img, 100, 150)\n",
    "    img = cv2.resize(img, (128, 128))     # (84, 84) for CNN, \n",
    "    img = img / 255.0                   # normalise to [0, 1]\n",
    "\n",
    "    return img                      # (1, 84, 84)\n",
    "\n",
    "\n",
    "# further preprocessing\n",
    "# normalise to [0, 1]\n",
    "# resize to 84x84\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# test screen processing\n",
    "\n",
    "while True:\n",
    "    img = get_screen()\n",
    "    img = process_screen_3rd(img)\n",
    "    cv2.imshow('screen', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 512):\n",
    "        super(CNN, self).__init__(observation_space, features_dim)\n",
    "\n",
    "        # add channels dimension\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_input_channels, 32, kernel_size=5, stride=4)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self._get_conv_output_dim(observation_space), features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.relu(self.conv1(observations))\n",
    "        self.feature_map1 = x  # Store feature map after conv1\n",
    "        x = self.relu(self.conv2(x))\n",
    "        self.feature_map2 = x  # Store feature map after conv2\n",
    "        x = self.relu(self.conv3(x))\n",
    "        self.feature_map3 = x  # Store feature map after conv3\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _get_conv_output_dim(self, observation_space):\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, *observation_space.shape)\n",
    "            x = self.relu(self.conv1(sample_input))\n",
    "            x = self.relu(self.conv2(x))\n",
    "            x = self.relu(self.conv3(x))\n",
    "            output_dim = x.numel()\n",
    "        return output_dim\n",
    "\n",
    "\n",
    "def visualise_feature_maps(model):\n",
    "    cnn_feature_extractor = model.policy.actor.features_extractor\n",
    "    cnn_feature_extractor.to(device)\n",
    "\n",
    "    image = get_screen()\n",
    "    image = process_screen_3rd(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = cnn_feature_extractor(image)\n",
    "    \n",
    "    feature_maps = [\n",
    "        cnn_feature_extractor.feature_map1,\n",
    "        cnn_feature_extractor.feature_map2,\n",
    "        cnn_feature_extractor.feature_map3\n",
    "    ]\n",
    "    \n",
    "    for idx, feature_map in enumerate(feature_maps, start=1):\n",
    "        feature_map = feature_map.squeeze(0)  # Remove batch dimension\n",
    "        num_features = feature_map.shape[0]\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for i in range(min(num_features, 64)):  # Limit to 64 feature maps for display\n",
    "            plt.subplot(8, 8, i+1)\n",
    "            plt.imshow(feature_map[i].cpu().numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Feature Map {idx}')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#Grad-CAM -> show useful regions of the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------controller\n",
    "gamepad = vg.VX360Gamepad()\n",
    "\n",
    "# 1,3 tensor\n",
    "def send_action(action):\n",
    "    steering, brake, throttle = action\n",
    "    gamepad.left_joystick_float(x_value_float=steering, y_value_float=0.0) # left/right\n",
    "    gamepad.left_trigger_float(value_float=brake) # brake\n",
    "    gamepad.right_trigger_float(value_float=throttle)\n",
    "    gamepad.update()\n",
    "\n",
    "def reset_key():\n",
    "    pydirectinput.press('enter')\n",
    "\n",
    "\n",
    "\n",
    "# create environment\n",
    "class TrackmaniaEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TrackmaniaEnv, self).__init__()\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1, 128, 128), dtype=np.float32)\n",
    "        # obs need to be in channel first format\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0, 0.0, 0.0]), # Steering angle from -1 (left) to 1 (right) throttle from 0 to 1, braking 0 to 1\n",
    "            high=np.array([1.0, 1.0, 1.0]), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.done = False           # ep done (crash or finish)\n",
    "        self.crash = False          # crash -> done\n",
    "        self.reward = 0             \n",
    "        \n",
    "        self.start_time = None\n",
    "        self.max_episode_length = 10000000\n",
    "        self.view = '3rd'\n",
    "\n",
    "        # Episode tracking variables\n",
    "        self.total_reward = 0\n",
    "        self.episode_length = 0\n",
    "\n",
    "        # bring to front\n",
    "        #window = gw.getWindowsWithTitle('Trackmania')[0]\n",
    "        #window.activate()\n",
    "        time.sleep(2)\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.total_reward = 0  # Reset total reward\n",
    "        self.episode_length = 0  # Reset episode length\n",
    "        reset_key()\n",
    "        time.sleep(1.5)  # Wait for green light\n",
    "        self.start_time = time.time()\n",
    "        obs, _, _ = self._get_observation()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # send action\n",
    "        send_action(action)\n",
    "\n",
    "        # get new obs\n",
    "        obs, speed, done_check = self._get_observation()\n",
    "        self.reward = self._calculate_reward(speed, done_check) # Calculate reward\n",
    "        self.total_reward += self.reward  # Update total reward\n",
    "        self.episode_length += 1  # Update episode length\n",
    "        self.done = self._check_done(speed, done_check)\n",
    "        self.truncated = self._check_truncated(speed)\n",
    "        \n",
    "        # Include episode information when done\n",
    "        info = {\"truncated\": self.truncated}\n",
    "        if self.done:\n",
    "            info['episode'] = {'r': self.total_reward, 'l': self.episode_length}\n",
    "            print(f\"Episode ended | Total Reward: {self.total_reward:.2f} | Length: {self.episode_length}\")\n",
    "        return obs, self.reward, self.done, self.truncated, info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        img = get_screen()\n",
    "        speed, done = get_speed_done(img)\n",
    "        speed = int(speed)\n",
    "        if self.view == 'pov':\n",
    "            img = process_screen_pov(img)\n",
    "        else:\n",
    "            img = process_screen_3rd(img)\n",
    "        img = np.expand_dims(img, axis=0) # add channel dim, should be 1, 128, 128\n",
    "        return img, speed, done\n",
    "    \n",
    "    def _calculate_reward(self, speed, done):\n",
    "        speed_factor = 0.01  # scale speed\n",
    "        min_speed_threshold = 110  # after 2 seconds\n",
    "        stall_penalty = -0.1  # Penalty for stalling or not moving\n",
    "        tt = time.time() - self.start_time #* 0.1\n",
    "        reward = 0\n",
    "        reward = speed * speed_factor #* tt\n",
    "        if speed < min_speed_threshold:\n",
    "            reward += stall_penalty\n",
    "\n",
    "        reward = np.round(reward, 4)\n",
    "        print(reward)\n",
    "        return reward\n",
    "        \n",
    "    def _check_done(self, speed, done):\n",
    "        if speed < 20 and time.time() - self.start_time > 5:\n",
    "            self.done = True\n",
    "        #if done:                # if ocr detects finish = done\n",
    "            #self.done = True\n",
    "        return self.done\n",
    "    \n",
    "    def _check_truncated(self, speed): # crash\n",
    "        return False\n",
    "    \n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = TrackmaniaEnv()\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'rl/trackmania_gym_SB3/models'\n",
    "\n",
    "learning_rate=3e-4\n",
    "buffer_size = 800_000 # 1,000,000\n",
    "batch_size = 512\n",
    "tau = 0.005\n",
    "gamma = 0.99\n",
    "train_freq= 1\n",
    "gradient_steps=1\n",
    "\n",
    "# create env\n",
    "vec_env = DummyVecEnv([make_env()])\n",
    "eval_env = DummyVecEnv([make_env()])\n",
    "\n",
    "# define model arguments\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CNN,       # or CNN\n",
    "    features_extractor_kwargs=dict(features_dim=512),\n",
    "    net_arch=dict(pi=[512, 256, 256], qf=[512, 256, 256]),    # actor and critic layers\n",
    "    normalize_images=False,  # already done in proprocess_screen()\n",
    ")\n",
    "\n",
    "# train \n",
    "def train():\n",
    "\n",
    "    # load or create new model\n",
    "    load = False\n",
    "    if load:\n",
    "        model_path = 'models/SAC_trackmania82500.zip'\n",
    "        if os.path.exists(model_path):\n",
    "            model = SAC.load(model_path, env=vec_env, tensorboard_log='logs/') \n",
    "            print(\"Loaded model from\", model_path)         \n",
    "    else:\n",
    "        model = SAC(\n",
    "            'CnnPolicy',\n",
    "            vec_env,\n",
    "            verbose=1,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log='logs/',\n",
    "            learning_rate=learning_rate,\n",
    "            buffer_size=buffer_size,  \n",
    "            batch_size=batch_size,     \n",
    "            tau=tau,\n",
    "            gamma=gamma,\n",
    "            train_freq=train_freq,\n",
    "            gradient_steps=gradient_steps,\n",
    "            ent_coef='auto',\n",
    "            optimize_memory_usage=True, \n",
    "            replay_buffer_kwargs=dict(handle_timeout_termination=False)\n",
    "        )\n",
    "        print(\"Created new model\")\n",
    "\n",
    "    # define evals\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env, \n",
    "        eval_freq=1000,  # how often to perform evaluation i.e. every 1000 timesteps.\n",
    "        best_model_save_path=\"models/best\",\n",
    "        log_path=\"logs/\",\n",
    "        verbose=1\n",
    "        \n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(save_freq=10000, \n",
    "                                             save_path='./models/', \n",
    "                                             name_prefix='SAC_model_{time}'\n",
    "                                             )\n",
    "\n",
    "    callback = CallbackList([eval_callback, checkpoint_callback])\n",
    "\n",
    "    # training loop\n",
    "    TIMESTEPS = 2500\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        model.learn(\n",
    "                    total_timesteps=TIMESTEPS, \n",
    "                    reset_num_timesteps=False, \n",
    "                    tb_log_name=f\"SAC_6\", \n",
    "                    callback=callback\n",
    "        )\n",
    "        model.save(f\"models/SAC_trackmania{TIMESTEPS*iters}\")\n",
    "\n",
    "        # Retrieve and print statistics from the model's ep_info_buffer\n",
    "        if len(model.ep_info_buffer) > 0:\n",
    "            ep_rewards = [ep_info['r'] for ep_info in model.ep_info_buffer]\n",
    "            ep_lengths = [ep_info['l'] for ep_info in model.ep_info_buffer]\n",
    "            avg_reward = np.mean(ep_rewards)\n",
    "            avg_length = np.mean(ep_lengths)\n",
    "            print(f\"Iteration: {iters} | Avg Reward: {avg_reward:.2f} | Avg Length: {avg_length:.2f}\")\n",
    "        else:\n",
    "            print(f\"Iteration: {iters} | No completed episodes in this iteration.\")\n",
    "\n",
    "\n",
    "        # Visualize feature maps every 10 iterations\n",
    "        if iters % 2 == 0:\n",
    "            visualise_feature_maps(model)\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 48.8 GiB for an array with shape (800000, 1, 1, 128, 128) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model from\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_path)         \n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSAC\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCnnPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvec_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle_timeout_termination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# define evals\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:157\u001b[0m, in \u001b[0;36mSAC.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_coef_optimizer: Optional[th\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:160\u001b[0m, in \u001b[0;36mSAC._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# Running mean and running var\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:189\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass an environment when using `HerReplayBuffer`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         replay_buffer_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[0;32m    193\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m    194\u001b[0m         n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs,\n\u001b[0;32m    195\u001b[0m         optimize_memory_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_memory_usage,\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule,\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs,\n\u001b[0;32m    204\u001b[0m )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\ausch\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:212\u001b[0m, in \u001b[0;36mReplayBuffer.__init__\u001b[1;34m(self, buffer_size, observation_space, action_space, device, n_envs, optimize_memory_usage, handle_timeout_termination)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplayBuffer does not support optimize_memory_usage = True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand handle_timeout_termination = True simultaneously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_memory_usage \u001b[38;5;241m=\u001b[39m optimize_memory_usage\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m optimize_memory_usage:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When optimizing memory, `observations` contains also the next observation\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_observations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_shape), dtype\u001b[38;5;241m=\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 48.8 GiB for an array with shape (800000, 1, 1, 128, 128) and data type float32"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 23.44 GiB\n"
     ]
    }
   ],
   "source": [
    "def print_available_memory():\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"Available memory: {mem.available / (1024 ** 3):.2f} GiB\")\n",
    "\n",
    "print_available_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
